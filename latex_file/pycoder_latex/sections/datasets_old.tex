\subsection{Datasets}

\begin{table}[]
    \centering
    \begin{tabular}{l|c|c|c}
        Dataset & Success & Indentation Error & Syntax Error \\
        \hline
        CodeXGLUE & 11.51 & 87.84 & 0.65 \\ 
        Our & 88.07 & 0.00 & 11.93 \\
    \end{tabular}
    \caption{Compare the parsing rate between datasets.}
    \label{tab:parsing rate}
\end{table}

Our dataset pre-processing is almost the same to CodeXGLUE pre-procssing. The difference is we preserve the indentation in the dataset because it keep the details and makes the dataset be more compilable (success to parse to AST). The comparation of parsing rate \kla{unclear the parsing rate: parse for Type or for AST? I thought we will not use AST so it should not be parsed for AST.} for the test set is shown in table \ref{tab:parsing rate}. In this paper we use our pre-processing dataset. However, to validate our model in CodeXGLUE competition in the RQ1, we train and test our model by CodeXGLUE dataset. \kla{need a clarification this part}

\begin{itemize}
    \item \textbf{Code dataset} We use python dataset \textit{PY150} from Raychev et al. \cite{raychev2016probabilistic}. The dataset contains 150,000 Python source files from Github. We follow data split in CodeXGLUE \cite{lu2021codexglue}. For token-level dataset, \textit{PY150} is split into 95,000 files for training, 5,000 files for validating, and 50,000 files for testing. For line-level dataset, CodeXGLUE does not release the ground-truth, however, we reconstruct the ground-truth from the same 10,000 testing samples in CodeXGLUE \cite{lu2021codexglue} using the testing data. \kla{how this part is done?} Basically, randomly cutting the line to be inputs and set the rest of the line until $\langle EOL \rangle$ as ground-truths is also acceptable. \kla{I'm not clear this part yet.}
    
    % \item \kla{I feel this could be part of the approach called data collection / to make the work more contributions. normally, anything in the experimental design will be on a standard basis. nothing new.} \textbf{Type dataset} To create type dataset, we use the standard python tokenizer lib \footnote{https://docs.python.org/3/library/tokenize.html\#module-tokenize}. We use exact type defined by the library in which transform to the placeholder $\langle EXACT\_TYPE \rangle$. For example, NAME type will be represented as $\langle NAME \rangle$. Overall the dataset has 54 types consisted of 8 primary types and 46 operational types. The pre-processing of each type of data are listed below.
    % \begin{itemize}
    %     \item \textbf{Discard} : We discard the following types ENDCODING, ENDMARKER, COMMENT.
    %     \item \textbf{Masked sensitive data} : We apply the same methods from CodeXGLUE \cite{lu2021codexglue} to masked the sensitive data of type STRING and NUMBER.
    %     \item \textbf{Transform} : Normally reserved keyword in python will be return as NAME type from tokenizer lib. We transform them to be KEYWORD type checking by keyword lib \footnote{https://docs.python.org/3/library/keyword.html}. We also transform NL and NEWLINE types to EOL to be consistent with CodeXGLUE standard.
    %     \item \textbf{Filter} : We filter ERRORTOKEN type that has the corresponding code token as empty string.
    %     \item \textbf{Preserve} : We preserve all the rest which are INDENT, DEDENT, and the exact operational types which represented in high-level as OPS.
    % \end{itemize}
    
    % \begin{table}[]
    %     \centering
    %     \begin{tabular}{l|c|c|c}
    %         Dataset & Success & Indentation Error & Syntax Error \\
    %         \hline
    %         CodeXGLUE & 11.51 & 87.84 & 0.65 \\ 
    %         Our & 88.07 & 0.00 & 11.93 \\
    %     \end{tabular}
    %     \caption{Compare the parsing rate between datasets.}
    %     \label{tab:parsing rate}
    % \end{table}
    
    % Primary types:
    % \texttt{<NAME>, <KEYWORD>, <NUMBER>, <STRING>, <INDENT>, <DEDENT>, <ERRORTOKEN>, <EOL>}
    
    % Operation types:
    % \texttt{<LPAR>, <RPAR>, <LSQB>, <RSQB>, <COLON>, <COMMA>, <SEMI>, <PLUS>, <MINUS>, <STAR>, <SLASH>, <VBAR>, <AMPER>, <LESS>, <GREATER>, <EQUAL>, <DOT>, <PERCENT>, <LBRACE>, <RBRACE>, <EQEQUAL>, <NOTEQUAL>, <LESSEQUAL>, <GREATEREQUAL>, <TILDE>, <CIRCUMFLEX>, <LEFTSHIFT>, <RIGHTSHIFT>, <DOUBLESTAR>, <PLUSEQUAL>, <MINEQUAL>, <STAREQUAL>, <SLASHEQUAL>, <PERCENTEQUAL>, <AMPEREQUAL>, <VBAREQUAL>, <CIRCUMFLEXEQUAL>, <LEFTSHIFTEQUAL>, <RIGHTSHIFTEQUAL>, <DOUBLESTAREQUAL>, <DOUBLESLASH>, <DOUBLESLASHEQUAL>, <AT>, <ATEQUAL>, <RARROW>, <ELLIPSIS>}
    
    % \item \kla{should not call BPE as dataset, but a data preprocessing step.} \textbf{Repeated type dataset / BPE type dataset} To train \gls{mtl} models, we need the datasets for main task and auxiliary task to be consistent with each others. For example, the code should be numerical at the same index of type NUMBER. Currently our code dataset and type dataset are consistent in word-level, however in sub-word-level from BPE, these dataset could be lapsed. Therefore, we propose repeated type dataset to solve this problem. Using BPE tokenizer to tokenize the words, we then repeating the type of corresponding word if the word is split by BPE. The algorithm of this process is shown in Algorithm~\ref{alg:repeat type dataset}. The result is the type dataset that has the same data length as code dataset when tokenized with BPE. 
    
    % \begin{algorithm}
    % \caption{For creating repeated type dataset}
    % \begin{algorithmic}
    % \For {i in length(predsList)}.
    %     \State $j \gets 0$
    %     \State $currentType \gets typeList[i][j]$
    %     \State $words \gets predsList[i]$
    %     \State $subwords\gets BPE(words)$
    %     \State $subwordTypes\gets list()$
    %     \For{subword in subwords}
    %         \If{isNewWord(subword)}
    %             \State $j \gets j + 1$
    %             \State $currentType \gets typeList[i][j]$
    %         \EndIf
    %         \State $subWordTypes.append(currentType)$
    %     \EndFor
    % \EndFor
    % \end{algorithmic}
    % \label{alg:repeat type dataset}
    % \end{algorithm}
    
\end{itemize}
